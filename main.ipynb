{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preprocessed_text\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Preprocess the text in the 'Text' column\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed_Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     20\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     21\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed_Text\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Replace 'Label' with the actual label column in your dataset\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# You can adjust the test size\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Your text preprocessing logic here\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpreprocessed_text\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_text' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Assuming you have a function preprocess_text for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return preprocessed_text\n",
    "\n",
    "# Preprocess the text in the 'Text' column\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,  # You can adjust the test size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'your_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'your_vectorizer.pkl')\n",
    "\n",
    "# Apply the model to the test set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "df_test_predictions = pd.DataFrame({'Text': X_test, 'Actual_Label': y_test, 'Predicted_Label': predictions})\n",
    "df_test_predictions.to_csv('test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Assuming you have a function preprocess_text for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text  # Update this line with your actual preprocessing logic\n",
    "\n",
    "# Preprocess the text in the 'Text' column\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,  # You can adjust the test size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'your_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'your_vectorizer.pkl')\n",
    "\n",
    "# Apply the model to the test set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "df_test_predictions = pd.DataFrame({'Text': X_test, 'Actual_Label': y_test, 'Predicted_Label': predictions})\n",
    "df_test_predictions.to_csv('test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7416666666666667\n",
      "Confusion Matrix:\n",
      "[[12  2  0  2  0  1]\n",
      " [ 0 13  2  2  0  2]\n",
      " [ 0  0 18  0  0  2]\n",
      " [ 0  1  1 20  1  1]\n",
      " [ 1  2  2  4 14  0]\n",
      " [ 0  1  0  4  0 12]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Analysis       0.92      0.71      0.80        17\n",
      "  Application       0.68      0.68      0.68        19\n",
      "Comprehension       0.78      0.90      0.84        20\n",
      "   Evaluation       0.62      0.83      0.71        24\n",
      "    Knowledge       0.93      0.61      0.74        23\n",
      "    Synthesis       0.67      0.71      0.69        17\n",
      "\n",
      "     accuracy                           0.74       120\n",
      "    macro avg       0.77      0.74      0.74       120\n",
      " weighted avg       0.77      0.74      0.74       120\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load and preprocess data\n",
    "# Assume you have a dataset with 'Text' and 'Label' columns\n",
    "df = pd.read_csv('BloomTaxonomy.csv')  # Update with your dataset path\n",
    "df.dropna(inplace=True)  # Handle missing values if any\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'Text' and 'Label'\n",
    "\n",
    "# Step 1: Define your text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    # For example, lowercasing and removing punctuation\n",
    "    preprocessed_text = text.lower()\n",
    "    preprocessed_text = ''.join([c for c in preprocessed_text if c.isalnum() or c.isspace()])\n",
    "    return preprocessed_text\n",
    "\n",
    "# Step 2: Apply the preprocessing function to the 'Text' column\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,  # You can adjust the test size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Step 5: Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 6: Build and train an NLP model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Step 9: Display the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Step 10: Visualize the results (example with a confusion matrix heatmap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model' is your trained NLP model\n",
    "with open('sentiment_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a dataset with columns 'Text' and 'Label'\n",
    "# Replace 'your_dataset.csv' with your actual dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new code me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8166666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your_model_svm.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Support Vector Machine\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))  # You can adjust the kernel as needed\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_svm.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your_model_random_forest.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],  # Replace 'Label' with the actual label column in your dataset\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Random Forest\n",
    "model = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_random_forest.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with XGBoost\n",
    "model = make_pipeline(TfidfVectorizer(), XGBClassifier(learning_rate=0.1, n_estimators=100, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_xgboost.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:187: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_knn.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with k-Nearest Neighbors\n",
    "model = make_pipeline(TfidfVectorizer(), KNeighborsClassifier(n_neighbors=5))  # You can adjust the number of neighbors (k) as needed\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_knn.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder_knn.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.49166666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_decision_tree.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Decision Tree\n",
    "model = make_pipeline(TfidfVectorizer(), DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_decision_tree.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder_decision_tree.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_svm_rbf.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Support Vector Machine (SVM)\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_svm_rbf.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder_svm_rbf.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_logistic_regression.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Logistic Regression\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_logistic_regression.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder_logistic_regression.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7083333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_mlp.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('BloomTaxonomy.csv')\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Your text preprocessing logic here\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Use LabelEncoder to encode string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Processed_Text'],\n",
    "    df['Label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a text classification pipeline with Multilayer Perceptron (MLP)\n",
    "model = make_pipeline(TfidfVectorizer(), MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'your_model_mlp.joblib')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "joblib.dump(label_encoder, 'label_encoder_mlp.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "195f7d4e7dfa36631d8b035cdcf7a97b6cf52e673cffc7538f8b1ac093d92219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
